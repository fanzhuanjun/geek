

# 上海レストランの分析０２

Team member：陳　浩嘉、　劉　嘉天

Data：[上海レストランのデータ](http://myeconomics.cn/geek/pyfile/pyfile/shanghai02.csv)





## 前処理

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.style import use
plt.style.use('fivethirtyeight')

plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签h
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号

df = pd.read_csv('c:/pwork/shanghai02.csv')
df.columns = ['F1', 'Lat', 'Lng', '記録数', '平均消費金額(组)', 'クラスター２', '平均消費金額', '味', 'サービス',
              '人气餐厅', '口コミ数', '雰囲気', 'クラスター', 'ジャンル', '行政区']

df['クラスター'] = df['クラスター'].str.replace('群集', 'クラスター')
df = df[df['クラスター'] != '未建立クラスター']
```



## 1. クラスター分析

### 1.1 k-means clustering

```python
# 教師なし学習
from sklearn.cluster import KMeans

# データがk平均法を利用して分類される
kmeans = KMeans(max_iter=50, n_clusters=4)　# 4種類分ける
col = ['平均消費金額', '味', 'サービス', '雰囲気', '口コミ数']
kmeans.fit(df[col])
df['cluser'] = kmeans.labels_
```

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/image-20200803120836348.png" width="600px" />



### 1.2 クラスタの分析

先にクラスタの基本統計量とジャンル最頻値の説明

```python
col = ['平均消費金額', '味', 'サービス', '雰囲気', '口コミ数']
df.groupby('クラスター')[col].mean().T.round(3)
```

| クラスター     | クラスター 1 |   クラスター 2 | クラスター 3 |                                       クラスター 4 |
| :------------- | -----------: | -------------: | -----------: | -------------------------------------------------: |
| 平均消費金額   |      138.873 |         44.672 |       63.283 |                                            116.607 |
| 味             |        8.438 |          7.046 |        7.667 |                                              8.207 |
| サービス       |        8.508 |          6.928 |        7.605 |                                              8.085 |
| 雰囲気         |        8.567 |          6.937 |        7.659 |                                              8.245 |
| 口コミ数       |     1158.281 |        259.173 |      542.857 |                                          12416.020 |
| ジャンル最頻値 |         洋食 | ファストフード |     デザート | [広東料理](https://ja.wikipedia.org/wiki/広東料理) |



クラスターの最頻値

```python
plt.figure(figsize=(16, 9))
df[df['クラスター'] == 'クラスター 1']['ジャンル'].value_counts().plot(kind='bar');plt.title('cluser 1');plt.show()
plt.figure(figsize=(16, 9))
df[df['クラスター'] == 'クラスター 2']['ジャンル'].value_counts().plot(kind='bar');plt.title('cluser 2');plt.show()
plt.figure(figsize=(16, 9))
df[df['クラスター'] == 'クラスター 3']['ジャンル'].value_counts().plot(kind='bar');plt.title('cluser 3');plt.show()
plt.figure(figsize=(16, 9))
df[df['クラスター'] == 'クラスター 4']['ジャンル'].value_counts().plot(kind='bar');plt.title('cluser 4');plt.show()
```

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/cluster1.png" width="600px" />

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/cluster2.png" width="600px" />

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/cluster3.png" width="600px" />

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/cluster4.png" width="600px" />



クラスターの統計量の分布

```python
cols = ['平均消費金額', '味', 'サービス', '雰囲気']

for col in cols:
    plt.figure(figsize=(12, 7))
    plt.hist(df[df['クラスター']=='クラスター 1'][col], 20, alpha=0.5, label='クラスター 1')
    plt.hist(df[df['クラスター']=='クラスター 2'][col], 20, alpha=0.5, label='クラスター 2')
    plt.hist(df[df['クラスター']=='クラスター 3'][col], 20, alpha=0.5, label='クラスター 3')
    plt.hist(df[df['クラスター']=='クラスター 4'][col], 20, alpha=0.5, label='クラスター 4')
    plt.legend(loc='upper right')
    plt.title(col)
    plt.show()
```

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/e1.png" width="600px" />

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/e2.png" width="600px" />

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/e3.png" width="600px" />

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/e4.png" width="600px" />





### 1.3 結果に基づいて推測する

クラスター 1：高級 (西洋料理) レストラン

特徴：消費金額高い、雰囲気、味、サービスも一番

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/shanghai2.png" width="600px" />



クラスター 2：サラリーマン向こうのお弁当

特徴：雰囲気、味、サービスの平均値一番低い、平均消費金額安い



<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/shanghai1.jpg" width="600px" />



クラスター 3：デザート派

特徴：最頻値はデザート、平均消費金額 CNY 64 くらい

<img src="https://dingyue.ws.126.net/2019/1213/80497fd0j00q2eqhh001oc200hs00bvg00hs00bv.jpg" width="600px" />



クラスター 4：家族の外食、会社の宴会

特徴：最頻値は**広東料理**と**火鍋**（ひなべ）、平均消費金額 116

<img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596432294689&di=2b198382c1fdac938e43cc9e486962f5&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20180225%2F68dcc38ddfb1461bb1bfbec71e8db6ae.jpeg" width="600px" />

<img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1596432205585&di=00641ad8ebbebeff238c796f7a80a0df&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20180222%2Fdb39fffb3f024cb3ba248e41b5cd2980.jpeg" width="600px" />







## 2. モデルの改善

前回は、主に特徴エンジニアリングを使用してモデルを改善し、一番の予測精度が **0.8286**。今回はディープラーニングを使用して予測する。



### 2.1 前回の概要

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/演示文稿1.jpg" alt="演示文稿1" width="700px" />



### 2.2 ディープラーニングの応用

```python
y1 = data02['口味']
X = data02.drop(['人均消费', '口味'], axis=1)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y1)
```

決定係数の関係 $R^2$ 

```python
import keras.backend as K
def r2(y_true, y_pred):
    a = K.square(y_pred - y_true)
    b = K.sum(a)
    c = K.mean(y_true)
    d = K.square(y_true - c)
    e = K.sum(d)
    f = 1 - b/e
    return f
```



最適の epochs を探す

```python
def build_model():
    model = models.Sequential()
    model.add(layers.Dense(256, activation='relu',
                           input_shape=(X_train.shape[1],)))
    model.add(layers.Dense(128, activation='relu'))
#     model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dense(1))
    model.compile(loss='mse', optimizer='rmsprop', metrics=['mae', r2])
    return model

num_epochs = 500
val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]
val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]
partial_train_data = np.concatenate(
    [train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]],
    axis=0)
partial_train_targets = np.concatenate(
    [train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], 
    axis=0)

model = build_model()
history = model.fit(partial_train_data, partial_train_targets,
                    validation_data=(val_data, val_targets),
                    epochs=num_epochs, batch_size=30)
```

```python
plt.plot(history.history['loss'][1:],label='train')
plt.plot(history.history['val_loss'][1:],label='test')
plt.legend()
plt.show()
```

<img src="https://github.com/fanzhuanjun/fanzhuanjun.github.io/raw/master/myimages/deep01.png" alt="演示文稿1" width="700px" />



`training_epochs = 200` でモデルを行う

```python
from keras import models
from keras import layers 

def build_model():
    model = models.Sequential()
    model.add(layers.Dense(256, activation='relu',
                           input_shape=(X_train.shape[1],)))
    model.add(layers.Dense(128, activation='relu'))
#     model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dense(1))
    model.compile(loss='mse', optimizer='rmsprop', metrics=['mae', r2])
    return model

model = build_model()
batch_size = 30
training_epochs = 200
history = model.fit(X_train, y_train, batch_size=batch_size, epochs=training_epochs)
```

```
Epoch 1/200
1372/1372 [==============================] - 3s 2ms/step - loss: 1244.6725 - mae: 6.3825 - r2: -3302.5356
Epoch 2/200
1372/1372 [==============================] - 3s 2ms/step - loss: 52.7075 - mae: 1.3866 - r2: -145.9738
Epoch 3/200
1372/1372 [==============================] - 3s 2ms/step - loss: 1.6794 - mae: 0.5389 - r2: -3.5610
...
...
Epoch 199/200
1372/1372 [==============================] - 3s 2ms/step - loss: 0.0762 - mae: 0.2036 - r2: 0.7812
Epoch 200/200
1372/1372 [==============================] - 3s 2ms/step - loss: 0.0759 - mae: 0.2035 - r2: 0.7831
```

予測の精度を計算する

```python
pred_test_y = model.predict(X_test)
from sklearn.metrics import r2_score
pred_acc = r2_score(y_test, pred_test_y)
print('予測精度：',pred_acc)
```

```
予測精度： 0.8455971356445738
```

