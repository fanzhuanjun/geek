```python
import pymysql

MYSQL_HOST = "localhost"
MYSQL_USER = "root"
MYSQL_PASSWORD = "123456"
MYSQL_PORT = 3306
MYSQL_DATABASE = "spiders"


class MySQL():
    def __init__(self, host=MYSQL_HOST, username=MYSQL_USER, password=MYSQL_PASSWORD, port=MYSQL_PORT,
                 database=MYSQL_DATABASE):
        """
        MySQL 初始化
        :param host:
        :param username:
        :param password:
        :param port:
        :param database:
        """
        try:
            self.db = pymysql.connect(host, username, password, database, charset='utf8', port=port)
            self.cursor = self.db.cursor()
        except pymysql.MySQLError as e:
            print(e.args)

    def insert(self, table, data):
        """
        插入数据
        :param table:
        :param data:
        :return:
        """
        keys = ', '.join(data.keys())
        values = ', '.join(['% s'] * len(data))
        sql_query = 'insert into % s (% s) values (% s)' % (table, keys, values)
        try:
            self.cursor.execute(sql_query, tuple(data.values()))
            self.db.commit()
        except pymysql.MySQLError as e:
            print(e.args)
            self.db.rollback()
```


```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import tqdm

def getPage(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
    }
    """
    获取网页内容
    """
    try:
        req = requests.get(url=url, headers = headers)
        bs = BeautifulSoup(req.text, 'html.parser')
        return bs
    except Exception as e:
        print('getPage error', e)

def get_content(bs):
    content = bs.find("div", {"id": "articlelistnew"})
    detail_contents = content.findAll("div", {"class": "articleh normal_post"})
    return detail_contents


def get_info(soup):
    title = ['views', 'comment', 'title', 'author', 'date', 'url1', 'url2']
    info = []
    scrapy_code = [
        r"""soup.find("span", {"class": "l1"}).text""",
        r"""soup.find("span", {"class": "l2"}).text""",
        r"""soup.find("span", {"class": "l3"}).text""",
        r"""soup.find("span", {"class": "l4"}).text""",
        r"""soup.find("span", {"class": "l5"}).text""",
        r"""soup.findAll("a")[0].attrs['href']""",
        r"""soup.findAll("a")[1].attrs['href']""",

    ]
    for i in scrapy_code:
        try:
            info.append(eval(i))
        except Exception as e:
            info.append(np.nan)
            print(e)
    return {k:v for k, v in zip(title, info)}

def main(url):
    bs = getPage(url)
    soups = get_content(bs)

    result_list = []

    for soup in soups:
        _ = get_info(soup)
        # result_list.append(_)
#         print(_)
        mydb.insert('dfcf', _)
    # return result_list
```


```python
# import multiprocessing

# mydb = MySQL()
# urls = [f"http://guba.eastmoney.com/list,zssh000001,f_{i}.html" for i in range(1, 10)]

# num_processes = multiprocessing.cpu_count() # 使用核心数
# # print("pool number: ", num_processes)
# pool = multiprocessing.Pool(processes=num_processes) # 实例化进程池
# pool.map(main,tqdm.tqdm(urls))
# pool.close()
# pool.join()
```

    100%|██████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 2259.05it/s]
    


```python
import multiprocessing


page = 10001
mydb = MySQL()
urls = [f"http://guba.eastmoney.com/list,zssh000001,f_{i}.html" for i in range(1, page)]

for url in tqdm.tqdm(urls):
    main(url)
```


```python
# url = "http://guba.eastmoney.com/list,zssh000001,f_2220.html"
# ss = main(url)
# ss
```


```python
# import pymysql

# db = pymysql.connect(host='localhost', user='root', password='123456', port=3306, db='spiders')
# cursor = db.cursor()
# # sql = 'CREATE TABLE IF NOT EXISTS students (id VARCHAR(255) NOT NULL, name VARCHAR(255) NOT NULL, age INT NOT NULL, score FLOAT NOT NULL, PRIMARY KEY (id))'
# sql = 'CREATE TABLE IF NOT EXISTS dfcf (views VARCHAR(255), comment INT, title VARCHAR(255), author VARCHAR(255), date VARCHAR(255), url1 VARCHAR(255), url2 VARCHAR(255))'
# cursor.execute(sql)
# db.close()
```


```python
def get_DataFrame(table):
    results = []
    
    db = pymysql.connect(host='localhost', user='root', password='123456', port=3306, db='spiders')
    cursor = db.cursor()
    
    # sql = 'SELECT * FROM students WHERE age >= 20'
    sql = f"SELECT * FROM {table}"

    try:
        cursor.execute(sql)
        print('Count:', cursor.rowcount)
        row = cursor.fetchone()
        
        while row:
            results.append(row)
            # print('Row:', row)
            row = cursor.fetchone()
            
    except:
        print('Error')
    
    db.close()
    return results
```


```python
import pandas as pd

cc = get_DataFrame(table='dfcf')
df = pd.DataFrame(cc)
```

    Count: 514315
    


```python
df.columns = ['views', 'comment', 'title', 'author', 'date', 'url1', 'url2']
```


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>views</th>
      <th>comment</th>
      <th>title</th>
      <th>author</th>
      <th>date</th>
      <th>url1</th>
      <th>url2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>28572</td>
      <td>178</td>
      <td>资讯 沈阳公寓项目卖出“白菜价”：2800元/平米 60平还不到</td>
      <td>财经评论资讯</td>
      <td>08-02 15:59</td>
      <td>/news,cjpl,1066035096.html</td>
      <td>/list,cjpl.html</td>
    </tr>
    <tr>
      <th>1</th>
      <td>43730</td>
      <td>702</td>
      <td>资讯 A股8月开门红：沪指大涨近2% 成交额突破1.5万亿</td>
      <td>财经评论资讯</td>
      <td>08-02 15:59</td>
      <td>/news,cjpl,1066022524.html</td>
      <td>/list,cjpl.html</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24418</td>
      <td>347</td>
      <td>资讯 每月领500元 四川攀枝花首个“二孩”家庭成功申请到育</td>
      <td>财经评论资讯</td>
      <td>08-02 15:59</td>
      <td>/news,cjpl,1066022195.html</td>
      <td>/list,cjpl.html</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6635</td>
      <td>46</td>
      <td>资讯 半导体重挫 大消费王者归来！8月股市如何走？机构火线</td>
      <td>财经评论资讯</td>
      <td>08-02 15:59</td>
      <td>/news,cjpl,1065913058.html</td>
      <td>/list,cjpl.html</td>
    </tr>
    <tr>
      <th>4</th>
      <td>37832</td>
      <td>118</td>
      <td>资讯 半导体突然崩了！三大千亿大白马暴跌！茅台触底狂拉7</td>
      <td>财经评论资讯</td>
      <td>08-02 15:59</td>
      <td>/news,cjpl,1065899410.html</td>
      <td>/list,cjpl.html</td>
    </tr>
  </tbody>
</table>
</div>


