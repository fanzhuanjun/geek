```python
import pandas as pd
import numpy as np
import time
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl
import datetime
# sns.set()
#正常显示画图时出现的中文和负号
from pylab import mpl
mpl.rcParams['font.sans-serif']=['SimHei']
mpl.rcParams['axes.unicode_minus']=False
#使用tushare获取数据
import tushare as ts
#设置好你的token
token = 'b15148f5ca285bd0e85bbc3f659daefff549ade3bba06fae6a037f03'
# token = "fc087ee503a6feac6cf5dde3e409dc44613d395bab12a4c4470707a4"
pro = ts.pro_api(token)
```

尝试构建基本面模型


```python
def get_daily(ts_code='', trade_date='', start_date='', end_date=''):
    for _ in range(3):
        try:
            if trade_date:
                df = pro.daily(ts_code=ts_code, trade_date=trade_date)
            else:
                df = pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)
        except Exception as e:
            print(e)
        else:
            return df
        
        
def get_basic(ts_code='', trade_date='', start_date='', end_date=''):
    for _ in range(3):
        try:
            if trade_date:
                df = pro.daily_basic(ts_code=ts_code, trade_date=trade_date)
            else:
                df = pro.daily_basic(ts_code=ts_code, start_date=start_date, end_date=end_date)
        except Exception as e:
            print(e)
        else:
            return df
```


```python
start_date='20100101'
end_date='20210702'
```


```python
# df_cal = pro.trade_cal(start_date=start_date, end_date=end_date)
# # exchange: 交易所 SSE上交所 SZSE深交所
# # is_open: 是否交易 0休市 1交易

# df_cal = df_cal.query('(exchange=="SSE") & (is_open==1)')
# for date in df_cal.cal_date:
#     df_daily = get_daily(trade_date=date)
#     df_basic = get_basic(trade_date=date).drop("close", axis=1)
#     df = pd.merge(df_daily, df_basic, on=['ts_code', 'trade_date'], how='inner')
#     df.to_csv(f"tudata/{date}.csv", encoding='utf_8_sig', index=None)
```


```python
p = "猪肉概念.xls"
stock_list = list(pd.read_excel(p).dropna()['证券代码'].values)
```


```python
len(stock_list)
```




    36




```python
df_final = pd.DataFrame()
count = 0

for ts_code in stock_list:
    df_daily = get_daily(ts_code=ts_code, start_date=start_date, end_date=end_date)
    df_basic = get_basic(ts_code=ts_code, start_date=start_date, end_date=end_date).drop("close", axis=1)
    _ = pd.merge(df_daily, df_basic, on=['ts_code', 'trade_date'], how='inner')
    df_final = df_final.append(_)
    count += 1
    print(f"{round(count/36, 2)*100}%")
```

    3.0%
    6.0%
    8.0%
    11.0%
    14.000000000000002%
    17.0%
    19.0%
    22.0%
    25.0%
    28.000000000000004%
    31.0%
    33.0%
    36.0%
    39.0%
    42.0%
    44.0%
    47.0%
    50.0%
    53.0%
    56.00000000000001%
    57.99999999999999%
    61.0%
    64.0%
    67.0%
    69.0%
    72.0%
    75.0%
    78.0%
    81.0%
    HTTPConnectionPool(host='127.0.0.1', port=28054): Read timed out.
    HTTPConnectionPool(host='127.0.0.1', port=28054): Read timed out.
    83.0%
    86.0%
    89.0%
    92.0%
    94.0%
    97.0%
    100.0%



```python
df_final.columns
```




    Index(['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close',
           'change', 'pct_chg', 'vol', 'amount', 'turnover_rate',
           'turnover_rate_f', 'volume_ratio', 'pe', 'pe_ttm', 'pb', 'ps', 'ps_ttm',
           'dv_ratio', 'dv_ttm', 'total_share', 'float_share', 'free_share',
           'total_mv', 'circ_mv'],
          dtype='object')




```python
df_final.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 71834 entries, 0 to 24
    Data columns (total 26 columns):
     #   Column           Non-Null Count  Dtype  
    ---  ------           --------------  -----  
     0   ts_code          71834 non-null  object 
     1   trade_date       71834 non-null  object 
     2   open             71834 non-null  float64
     3   high             71834 non-null  float64
     4   low              71834 non-null  float64
     5   close            71834 non-null  float64
     6   pre_close        71834 non-null  float64
     7   change           71834 non-null  float64
     8   pct_chg          71834 non-null  float64
     9   vol              71834 non-null  float64
     10  amount           71834 non-null  float64
     11  turnover_rate    71834 non-null  float64
     12  turnover_rate_f  71834 non-null  float64
     13  volume_ratio     71724 non-null  float64
     14  pe               68121 non-null  float64
     15  pe_ttm           66103 non-null  float64
     16  pb               71282 non-null  float64
     17  ps               71834 non-null  float64
     18  ps_ttm           71834 non-null  float64
     19  dv_ratio         47782 non-null  object 
     20  dv_ttm           48968 non-null  object 
     21  total_share      71834 non-null  float64
     22  float_share      71834 non-null  float64
     23  free_share       71777 non-null  float64
     24  total_mv         71834 non-null  float64
     25  circ_mv          71834 non-null  float64
    dtypes: float64(22), object(4)
    memory usage: 14.8+ MB



```python
df_final['trade_date'] = pd.to_datetime(df_final['trade_date'])
```


```python
df_final = df_final.sort_values(['ts_code', 'trade_date']).reset_index().drop("index", axis=1)
```


```python
df_final['pct_chg'] = df_final['pct_chg']/100
```


```python
df_final.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>trade_date</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>...</th>
      <th>pb</th>
      <th>ps</th>
      <th>ps_ttm</th>
      <th>dv_ratio</th>
      <th>dv_ttm</th>
      <th>total_share</th>
      <th>float_share</th>
      <th>free_share</th>
      <th>total_mv</th>
      <th>circ_mv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000002.SZ</td>
      <td>2010-01-04</td>
      <td>10.85</td>
      <td>10.87</td>
      <td>10.60</td>
      <td>10.60</td>
      <td>10.81</td>
      <td>-0.21</td>
      <td>-0.0194</td>
      <td>969832.53</td>
      <td>...</td>
      <td>3.3354</td>
      <td>2.8432</td>
      <td>2.4284</td>
      <td>0.4717</td>
      <td>0.4717</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.165492e+07</td>
      <td>1.023546e+07</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.SZ</td>
      <td>2010-01-05</td>
      <td>10.51</td>
      <td>10.52</td>
      <td>10.20</td>
      <td>10.36</td>
      <td>10.60</td>
      <td>-0.24</td>
      <td>-0.0226</td>
      <td>1848620.78</td>
      <td>...</td>
      <td>3.2599</td>
      <td>2.7789</td>
      <td>2.3734</td>
      <td>0.4826</td>
      <td>0.4826</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.139104e+07</td>
      <td>1.000371e+07</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000002.SZ</td>
      <td>2010-01-06</td>
      <td>10.35</td>
      <td>10.51</td>
      <td>10.20</td>
      <td>10.36</td>
      <td>10.36</td>
      <td>0.00</td>
      <td>0.0000</td>
      <td>1358604.06</td>
      <td>...</td>
      <td>3.2599</td>
      <td>2.7789</td>
      <td>2.3734</td>
      <td>0.4826</td>
      <td>0.4826</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.139104e+07</td>
      <td>1.000371e+07</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000002.SZ</td>
      <td>2010-01-07</td>
      <td>10.36</td>
      <td>10.43</td>
      <td>10.24</td>
      <td>10.28</td>
      <td>10.36</td>
      <td>-0.08</td>
      <td>-0.0077</td>
      <td>1152441.98</td>
      <td>...</td>
      <td>3.2347</td>
      <td>2.7574</td>
      <td>2.3551</td>
      <td>0.4864</td>
      <td>0.4864</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.130308e+07</td>
      <td>9.926466e+06</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000002.SZ</td>
      <td>2010-01-08</td>
      <td>10.28</td>
      <td>10.38</td>
      <td>10.19</td>
      <td>10.35</td>
      <td>10.28</td>
      <td>0.07</td>
      <td>0.0068</td>
      <td>1085304.22</td>
      <td>...</td>
      <td>3.2568</td>
      <td>2.7762</td>
      <td>2.3712</td>
      <td>0.4831</td>
      <td>0.4831</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.138004e+07</td>
      <td>9.994058e+06</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 26 columns</p>
</div>




```python
df_final['pb_scaler'] = df_final.groupby('trade_date')['pb'].apply(lambda x: (x - np.mean(x)) / (np.std(x)))
```


```python
df_final.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 71834 entries, 0 to 71833
    Data columns (total 28 columns):
     #   Column           Non-Null Count  Dtype         
    ---  ------           --------------  -----         
     0   ts_code          71834 non-null  object        
     1   trade_date       71834 non-null  datetime64[ns]
     2   open             71834 non-null  float64       
     3   high             71834 non-null  float64       
     4   low              71834 non-null  float64       
     5   close            71834 non-null  float64       
     6   pre_close        71834 non-null  float64       
     7   change           71834 non-null  float64       
     8   pct_chg          71834 non-null  float64       
     9   vol              71834 non-null  float64       
     10  amount           71834 non-null  float64       
     11  turnover_rate    71834 non-null  float64       
     12  turnover_rate_f  71834 non-null  float64       
     13  volume_ratio     71724 non-null  float64       
     14  pe               68121 non-null  float64       
     15  pe_ttm           66103 non-null  float64       
     16  pb               71282 non-null  float64       
     17  ps               71834 non-null  float64       
     18  ps_ttm           71834 non-null  float64       
     19  dv_ratio         47782 non-null  object        
     20  dv_ttm           48968 non-null  object        
     21  total_share      71834 non-null  float64       
     22  float_share      71834 non-null  float64       
     23  free_share       71777 non-null  float64       
     24  total_mv         71834 non-null  float64       
     25  circ_mv          71834 non-null  float64       
     26  variable_step1   0 non-null      object        
     27  pb_scaler        71282 non-null  float64       
    dtypes: datetime64[ns](1), float64(23), object(4)
    memory usage: 15.3+ MB



```python
import statsmodels.api as sm

def get_OLS(X, y):
    X = sm.add_constant(X)
    mod = sm.OLS(y, X)
    res = mod.fit()
    return res
```


```python
date = "2015-01-08"

_ = df_final[df_final['trade_date'] == date][['pb_scaler', 'pct_chg']]
_ = _.dropna()
print(_.shape)
X = _[['pb_scaler']]
y = _['pct_chg']
```

    (25, 2)



```python
res = get_OLS(X, y)
```


```python
res.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>pct_chg</td>     <th>  R-squared:         </th> <td>   0.132</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.094</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.487</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 03 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0746</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>17:53:51</td>     <th>  Log-Likelihood:    </th> <td>  61.572</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    25</td>      <th>  AIC:               </th> <td>  -119.1</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    23</td>      <th>  BIC:               </th> <td>  -116.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>     <td>    0.0077</td> <td>    0.004</td> <td>    1.791</td> <td> 0.086</td> <td>   -0.001</td> <td>    0.017</td>
</tr>
<tr>
  <th>pb_scaler</th> <td>    0.0080</td> <td>    0.004</td> <td>    1.867</td> <td> 0.075</td> <td>   -0.001</td> <td>    0.017</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.960</td> <th>  Durbin-Watson:     </th> <td>   1.461</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.619</td> <th>  Jarque-Bera (JB):  </th> <td>   0.458</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.332</td> <th>  Prob(JB):          </th> <td>   0.795</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.011</td> <th>  Cond. No.          </th> <td>    1.00</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.




```python
res.params['pb_scaler']
```




    0.00802615040244489




```python
factor_prenium = []

df_cal = pro.trade_cal(start_date=start_date, end_date=end_date)
# exchange: 交易所 SSE上交所 SZSE深交所
# is_open: 是否交易 0休市 1交易
df_cal = df_cal.query('(exchange=="SSE") & (is_open==1)')
for date in df_cal.cal_date:
    _ = df_final[df_final['trade_date'] == date][['pb_scaler', 'pct_chg']]
    _ = _.dropna()
    print(_.shape)
    X = _[['pb_scaler']]
    y = _['pct_chg']
    res = get_OLS(X, y)
    pb_beta = res.params['pb_scaler']
    factor_prenium.append([date, pb_beta])
```





```python
pb_df = pd.DataFrame(factor_prenium, columns=['date', 'pb_beta'])
```


```python
pb_df.set_index("date")['pb_beta'].plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x201ff1fa160>




![png](%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_files/%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_23_1.png)



```python
pb_df['pb_beta_cum'] = (pb_df['pb_beta'] + 1).cumprod()
```


```python
pb_df.set_index("date")['pb_beta_cum'].plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2018381eee0>




![png](%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_files/%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_25_1.png)



```python
pb_df['pb_beta_shift1'] = pb_df['pb_beta'].shift(1)
```


```python
ss = pb_df.set_index("date")['pb_beta']
```


```python
ss
```




    date
    20100104    0.009904
    20100105   -0.007811
    20100106    0.000761
    20100107    0.000890
    20100108   -0.002367
                  ...   
    20210628    0.001835
    20210629   -0.000095
    20210630    0.003989
    20210701    0.001270
    20210702   -0.001245
    Name: pb_beta, Length: 2794, dtype: float64




```python
# 结果并不显著？
# 到底如何制作基本面模型？
import statsmodels.api as sm


model = sm.tsa.arima.ARIMA(ss, order=(5, 0, 1))
model_fit = model.fit()

model_fit.summary()
```

    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:216: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.
      then falling back to try again with the model row labels as the base
    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:216: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.
      then falling back to try again with the model row labels as the base
    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:216: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.
      then falling back to try again with the model row labels as the base





<table class="simpletable">
<caption>SARIMAX Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>pb_beta</td>     <th>  No. Observations:  </th>    <td>2794</td>   
</tr>
<tr>
  <th>Model:</th>            <td>ARIMA(5, 0, 1)</td>  <th>  Log Likelihood     </th>  <td>10138.759</td>
</tr>
<tr>
  <th>Date:</th>            <td>Sat, 03 Jul 2021</td> <th>  AIC                </th> <td>-20261.519</td>
</tr>
<tr>
  <th>Time:</th>                <td>18:23:43</td>     <th>  BIC                </th> <td>-20214.037</td>
</tr>
<tr>
  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>-20244.378</td>
</tr>
<tr>
  <th></th>                      <td> - 2794</td>     <th>                     </th>      <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>      <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>    0.0008</td> <td>    0.000</td> <td>    4.889</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>
</tr>
<tr>
  <th>ar.L1</th>  <td>    0.0566</td> <td>    0.313</td> <td>    0.181</td> <td> 0.857</td> <td>   -0.558</td> <td>    0.671</td>
</tr>
<tr>
  <th>ar.L2</th>  <td>   -0.0074</td> <td>    0.041</td> <td>   -0.182</td> <td> 0.856</td> <td>   -0.087</td> <td>    0.072</td>
</tr>
<tr>
  <th>ar.L3</th>  <td>    0.0009</td> <td>    0.017</td> <td>    0.052</td> <td> 0.959</td> <td>   -0.032</td> <td>    0.034</td>
</tr>
<tr>
  <th>ar.L4</th>  <td>    0.0225</td> <td>    0.014</td> <td>    1.563</td> <td> 0.118</td> <td>   -0.006</td> <td>    0.051</td>
</tr>
<tr>
  <th>ar.L5</th>  <td>   -0.0311</td> <td>    0.019</td> <td>   -1.616</td> <td> 0.106</td> <td>   -0.069</td> <td>    0.007</td>
</tr>
<tr>
  <th>ma.L1</th>  <td>    0.0575</td> <td>    0.315</td> <td>    0.183</td> <td> 0.855</td> <td>   -0.560</td> <td>    0.675</td>
</tr>
<tr>
  <th>sigma2</th> <td> 4.127e-05</td> <td> 1.77e-07</td> <td>  233.182</td> <td> 0.000</td> <td> 4.09e-05</td> <td> 4.16e-05</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Ljung-Box (Q):</th>          <td>64.49</td> <th>  Jarque-Bera (JB):  </th> <td>1893526.63</td>
</tr>
<tr>
  <th>Prob(Q):</th>                <td>0.01</td>  <th>  Prob(JB):          </th>    <td>0.00</td>   
</tr>
<tr>
  <th>Heteroskedasticity (H):</th> <td>0.74</td>  <th>  Skew:              </th>    <td>6.04</td>   
</tr>
<tr>
  <th>Prob(H) (two-sided):</th>    <td>0.00</td>  <th>  Kurtosis:          </th>   <td>129.96</td>  
</tr>
</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step).




```python
model_fit.forecast()
```

    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:580: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.
      if date_index and not has_freq:





    2794    0.000528
    dtype: float64




```python
# X = pb_df.dropna()['pb_beta_shift1']
# y = pb_df.dropna()['pb_beta']
# get_OLS(X, y).summary()
```

# 经济因子模型


```python
df_final['BM'] = 1 / df_final['pb']
```


```python
df_final['pb_scaler'] = df_final.groupby('trade_date')['BM'].apply(lambda x: (x - np.mean(x)) / (np.std(x)))
# df_final['pb_scaler'] = df_final.groupby('trade_date')['circ_mv'].apply(lambda x: (x - np.mean(x)) / (np.std(x)))
```


```python
df_final.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>trade_date</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>...</th>
      <th>dv_ratio</th>
      <th>dv_ttm</th>
      <th>total_share</th>
      <th>float_share</th>
      <th>free_share</th>
      <th>total_mv</th>
      <th>circ_mv</th>
      <th>variable_step1</th>
      <th>pb_scaler</th>
      <th>BM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000002.SZ</td>
      <td>2010-01-04</td>
      <td>10.85</td>
      <td>10.87</td>
      <td>10.60</td>
      <td>10.60</td>
      <td>10.81</td>
      <td>-0.21</td>
      <td>-0.0194</td>
      <td>969832.53</td>
      <td>...</td>
      <td>0.4717</td>
      <td>0.4717</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.165492e+07</td>
      <td>1.023546e+07</td>
      <td>NaN</td>
      <td>1.405906</td>
      <td>0.299814</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.SZ</td>
      <td>2010-01-05</td>
      <td>10.51</td>
      <td>10.52</td>
      <td>10.20</td>
      <td>10.36</td>
      <td>10.60</td>
      <td>-0.24</td>
      <td>-0.0226</td>
      <td>1848620.78</td>
      <td>...</td>
      <td>0.4826</td>
      <td>0.4826</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.139104e+07</td>
      <td>1.000371e+07</td>
      <td>NaN</td>
      <td>1.576210</td>
      <td>0.306758</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000002.SZ</td>
      <td>2010-01-06</td>
      <td>10.35</td>
      <td>10.51</td>
      <td>10.20</td>
      <td>10.36</td>
      <td>10.36</td>
      <td>0.00</td>
      <td>0.0000</td>
      <td>1358604.06</td>
      <td>...</td>
      <td>0.4826</td>
      <td>0.4826</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.139104e+07</td>
      <td>1.000371e+07</td>
      <td>NaN</td>
      <td>1.566894</td>
      <td>0.306758</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000002.SZ</td>
      <td>2010-01-07</td>
      <td>10.36</td>
      <td>10.43</td>
      <td>10.24</td>
      <td>10.28</td>
      <td>10.36</td>
      <td>-0.08</td>
      <td>-0.0077</td>
      <td>1152441.98</td>
      <td>...</td>
      <td>0.4864</td>
      <td>0.4864</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.130308e+07</td>
      <td>9.926466e+06</td>
      <td>NaN</td>
      <td>1.534409</td>
      <td>0.309148</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000002.SZ</td>
      <td>2010-01-08</td>
      <td>10.28</td>
      <td>10.38</td>
      <td>10.19</td>
      <td>10.35</td>
      <td>10.28</td>
      <td>0.07</td>
      <td>0.0068</td>
      <td>1085304.22</td>
      <td>...</td>
      <td>0.4831</td>
      <td>0.4831</td>
      <td>1.099521e+06</td>
      <td>965609.491</td>
      <td>803700.0144</td>
      <td>1.138004e+07</td>
      <td>9.994058e+06</td>
      <td>NaN</td>
      <td>1.514091</td>
      <td>0.307050</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 29 columns</p>
</div>




```python
data = df_final.copy()
q = 5
labels = ['low', *[i for i in range(2, q)] , 'high']
qcut_func = partial(pd.qcut, q=q, labels=labels)

data['group'] = data.groupby('trade_date')['pb_scaler'].apply(qcut_func)
data['group_lag1'] = data.groupby('ts_code')['group'].shift(1)
```

# 可以发现，用当期和用上一期分组是由很大差别的


```python
_ = data.groupby(['group_lag1', 'trade_date'])['pct_chg'].mean()
# _ = data.groupby(['group', 'trade_date'])['pct_chg'].mean()
_
```




    group_lag1  trade_date
    low         2010-01-04         NaN
                2010-01-05   -0.001533
                2010-01-06    0.004833
                2010-01-07   -0.018767
                2010-01-08   -0.002367
                                ...   
    high        2021-06-28    0.040384
                2021-06-29   -0.021104
                2021-06-30   -0.007132
                2021-07-01   -0.003546
                2021-07-02   -0.008403
    Name: pct_chg, Length: 13970, dtype: float64




```python
new = _.unstack().T
new
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>group_lag1</th>
      <th>low</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>high</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010-01-04</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2010-01-05</th>
      <td>-0.001533</td>
      <td>0.015600</td>
      <td>0.008600</td>
      <td>0.009300</td>
      <td>0.015800</td>
    </tr>
    <tr>
      <th>2010-01-06</th>
      <td>0.004833</td>
      <td>-0.002400</td>
      <td>-0.019700</td>
      <td>-0.014467</td>
      <td>-0.012500</td>
    </tr>
    <tr>
      <th>2010-01-07</th>
      <td>-0.018767</td>
      <td>-0.016433</td>
      <td>-0.014233</td>
      <td>0.000933</td>
      <td>-0.023600</td>
    </tr>
    <tr>
      <th>2010-01-08</th>
      <td>-0.002367</td>
      <td>0.020967</td>
      <td>-0.028500</td>
      <td>-0.002833</td>
      <td>0.009367</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-06-28</th>
      <td>0.042776</td>
      <td>0.040766</td>
      <td>0.021188</td>
      <td>0.052689</td>
      <td>0.040384</td>
    </tr>
    <tr>
      <th>2021-06-29</th>
      <td>-0.030419</td>
      <td>-0.020090</td>
      <td>-0.017052</td>
      <td>-0.026262</td>
      <td>-0.021104</td>
    </tr>
    <tr>
      <th>2021-06-30</th>
      <td>-0.001405</td>
      <td>-0.021419</td>
      <td>-0.003116</td>
      <td>-0.004716</td>
      <td>-0.007132</td>
    </tr>
    <tr>
      <th>2021-07-01</th>
      <td>-0.005393</td>
      <td>-0.014865</td>
      <td>-0.007359</td>
      <td>-0.008831</td>
      <td>-0.003546</td>
    </tr>
    <tr>
      <th>2021-07-02</th>
      <td>-0.013366</td>
      <td>0.018994</td>
      <td>-0.002145</td>
      <td>-0.010521</td>
      <td>-0.008403</td>
    </tr>
  </tbody>
</table>
<p>2794 rows × 5 columns</p>
</div>




```python
(new+1).cumprod()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>group_lag1</th>
      <th>low</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>high</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010-01-04</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2010-01-05</th>
      <td>0.998467</td>
      <td>1.015600</td>
      <td>1.008600</td>
      <td>1.009300</td>
      <td>1.015800</td>
    </tr>
    <tr>
      <th>2010-01-06</th>
      <td>1.003293</td>
      <td>1.013163</td>
      <td>0.988731</td>
      <td>0.994699</td>
      <td>1.003103</td>
    </tr>
    <tr>
      <th>2010-01-07</th>
      <td>0.984464</td>
      <td>0.996513</td>
      <td>0.974658</td>
      <td>0.995627</td>
      <td>0.979429</td>
    </tr>
    <tr>
      <th>2010-01-08</th>
      <td>0.982134</td>
      <td>1.017406</td>
      <td>0.946880</td>
      <td>0.992806</td>
      <td>0.988603</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2021-06-28</th>
      <td>1.293472</td>
      <td>6.353126</td>
      <td>2.585024</td>
      <td>7.639252</td>
      <td>14.235923</td>
    </tr>
    <tr>
      <th>2021-06-29</th>
      <td>1.254125</td>
      <td>6.225489</td>
      <td>2.540943</td>
      <td>7.438633</td>
      <td>13.935482</td>
    </tr>
    <tr>
      <th>2021-06-30</th>
      <td>1.252364</td>
      <td>6.092146</td>
      <td>2.533027</td>
      <td>7.403553</td>
      <td>13.836100</td>
    </tr>
    <tr>
      <th>2021-07-01</th>
      <td>1.245609</td>
      <td>6.001588</td>
      <td>2.514387</td>
      <td>7.338173</td>
      <td>13.787033</td>
    </tr>
    <tr>
      <th>2021-07-02</th>
      <td>1.228961</td>
      <td>6.115584</td>
      <td>2.508993</td>
      <td>7.260966</td>
      <td>13.671187</td>
    </tr>
  </tbody>
</table>
<p>2794 rows × 5 columns</p>
</div>




```python
new.plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2018a6cce20>




![png](%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_files/%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_41_1.png)



```python
# plt图片清晰
#figsize(12.5, 4) # 设置 figsize
plt.rcParams['savefig.dpi'] = 300 #图片像素
plt.rcParams['figure.dpi'] = 300 #分辨率
```


```python
(new+1).cumprod().plot(figsize=(13, 9))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2018ac0d220>




![png](%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_files/%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_43_1.png)



```python
((new['high'] - new['low']) + 1).cumprod().plot(figsize=(13, 9))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2018f277af0>




![png](%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_files/%E5%9F%BA%E6%9C%AC%E9%9D%A2%E6%A8%A1%E5%9E%8B_44_1.png)


# ARMA模型预测不够准确


```python
ss = (new['high'] - new['low'])
```


```python
model = sm.tsa.arima.ARIMA(ss, order=(5, 0, 1))
model_fit = model.fit()

print(model_fit.summary())
```

    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:216: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.
      then falling back to try again with the model row labels as the base
    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:216: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.
      then falling back to try again with the model row labels as the base
    c:\users\13631\appdata\local\programs\python\python38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:216: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.
      then falling back to try again with the model row labels as the base


                                   SARIMAX Results                                
    ==============================================================================
    Dep. Variable:                      y   No. Observations:                 2794
    Model:                 ARIMA(5, 0, 1)   Log Likelihood                7745.974
    Date:                Sun, 04 Jul 2021   AIC                         -15475.948
    Time:                        14:46:26   BIC                         -15428.466
    Sample:                             0   HQIC                        -15458.807
                                   - 2794                                         
    Covariance Type:                  opg                                         
    ==============================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
    ------------------------------------------------------------------------------
    const          0.0008      0.000      2.586      0.010       0.000       0.001
    ar.L1          0.0420      0.801      0.052      0.958      -1.528       1.612
    ar.L2         -0.0136      0.070     -0.193      0.847      -0.151       0.124
    ar.L3          0.0033      0.021      0.159      0.873      -0.038       0.044
    ar.L4          0.0226      0.016      1.425      0.154      -0.008       0.054
    ar.L5         -0.0200      0.023     -0.860      0.390      -0.066       0.026
    ma.L1          0.0432      0.801      0.054      0.957      -1.527       1.613
    sigma2         0.0002   4.67e-06     48.933      0.000       0.000       0.000
    ===================================================================================
    Ljung-Box (Q):                       35.65   Jarque-Bera (JB):               343.87
    Prob(Q):                              0.67   Prob(JB):                         0.00
    Heteroskedasticity (H):               1.02   Skew:                             0.12
    Prob(H) (two-sided):                  0.73   Kurtosis:                         4.70
    ===================================================================================
    
    Warnings:
    [1] Covariance matrix calculated using the outer product of gradients (complex-step).



```python
ss
```




    trade_date
    2010-01-04         NaN
    2010-01-05    0.017333
    2010-01-06   -0.017333
    2010-01-07   -0.004833
    2010-01-08    0.011733
                    ...   
    2021-06-28   -0.002392
    2021-06-29    0.009315
    2021-06-30   -0.005727
    2021-07-01    0.001847
    2021-07-02    0.004963
    Length: 2794, dtype: float64




```python

```
